энтропи от поворот превращение широко используемый естественных точных науках термин впервые введён рамках термодинамики как функция состояния системы определяющая меру необратимого рассеивания энергии статистической физике энтропия характеризует вероятность осуществления какого либо состояния кроме физики термин широко употребляется математике теории информации математической статистике для энтропии чаще математике встречается также название шенноновская информация или количество информации по шеннону энтропия может как мера некоторой системы например какого либо опыта испытания который может иметь разные исходы значит количество информации таким образом другой интерпретацией энтропии является информационная ёмкость системы данной интерпретацией связан тот факт что создатель понятия энтропии теории информации клод шеннон сначала хотел назвать эту величину информацией понятие информационной энтропии применяется как теории информации математической статистике так статистической физике энтропия гиббса её упрощённый вариант энтропия больцмана математический смысл информационной энтропии это логарифм числа доступных состояний системы основание логарифма может быть различным но большим оно определяет единицу измерения энтропии такая функция от числа состояний обеспечивает свойство аддитивности энтропии для независимых систем причём если состояния различаются по степени доступности то есть не равновероятны под числом состояний системы нужно понимать их эффективное количество которое определяется следующим образом пусть состояния системы равновероятны имеют вероятность тогда число состояний случае разных вероятностей состояний рассмотрим величину где эффективное количество состояний из данной интерпретации непосредственно вытекает выражение для информационной энтропии шеннона подобная интерпретация справедлива для энтропии реньи которая является одним из обобщений понятия информационная энтропия но этом случае иначе определяется эффективное количество состояний системы можно показать что энтропии реньи соответствует эффективное количество состояний определяемое как среднее степенное взвешенное параметром от величин следует заметить что интерпретация формулы шеннона на основе взвешенного среднего не является её обоснованием строгий вывод этой формулы может быть получен из комбинаторных соображений помощью асимптотической формулы стирлинга заключается том что комбинаторность распределения то есть число способов которыми оно может быть реализовано после взятия логарифма нормировки пределе совпадает выражением для энтропии виде предложенном шенноном широком смысле каком слово часто употребляется быту энтропия означает меру или хаотичности системы чем меньше элементы системы подчинены какому либо порядку тем выше энтропия величина противоположная энтропии именуется негэнтропией или реже экстропией аксиоматическое определение энтропии выражение для информационной энтропии может быть выведено на основе некоторой системы аксиом одним из подходов является следующая система аксиом известная как система аксиом хинчина пусть некоторая система может пребывать каждом из доступных состояний вероятностью где энтропия является функцией только вероятностей для любой системы справедливо где система равномерным распределением вероятностей если добавить систему состояние то энтропия системы не изменится энтропия совокупности двух систем имеет вид где средняя по ансамблю условная энтропия указанный набор аксиом однозначно приводит формуле для энтропии шеннона некоторые авторы обращают внимание на последней аксиомы хинчина действительно более простым очевидным является требование аддитивности энтропии для независимых систем таким образом последняя аксиома может быть заменена следующим условием энтропия совокупности двух независимых систем имеет вид оказывается система аксиом пунктом приводит не только энтропии шеннона но энтропии реньи употребление различных дисциплинах энтропия функция характеризующая меру необратимой диссипации энергии ней статистической физике характеризует вероятность осуществления некоторого состояния системы математической статистике мера распределения вероятностей информационная энтропия теории информации мера источника сообщений определяемая вероятностями появления тех или иных символов при их передаче энтропия динамической системы теории динамических систем мера хаотичности поведении траекторий системы энтропия формальное обобщение понятия энтропии для непрерывных распределений энтропия отражения часть информации дискретной системе которая не воспроизводится при отражении системы через совокупность своих частей энтропия теории управления мера состояния или поведения системы данных условиях термодинамике понятие энтропии впервые было введено клаузиусом термодинамике году для определения меры необратимого рассеивания энергии меры отклонения реального процесса от идеального определённая как сумма приведённых теплот она является функцией состояния остаётся постоянной при замкнутых обратимых процессах тогда как необратимых замкнутых её изменение всегда положительно открытой системе может происходить уменьшение энтропии рассматриваемой системы за счет уноса энергии например виде излучения при этом полная энтропия окружающей среды увеличивается математически энтропия определяется как функция состояния системы определённая точностью до произвольной постоянной разность энтропий двух равновесных состояниях по определению равна приведённому количеству тепла которое надо сообщить системе чтобы перевести её из состояния состояние по любому пути так как энтропия определена точностью до произвольной постоянной то можно условно принять состояние за начальное положить тогда здесь интеграл берется для произвольного процесса дифференциал функции имеет вид энтропия устанавливает связь между макро микро состояниями особенность данной характеристики заключается том что это единственная функция физике которая показывает направленность процессов поскольку энтропия является функцией состояния то она не зависит от того как осуществлён переход из одного состояния системы другое определяется только начальным конечным состояниями системы см также информационная энтропия энтропия реньи энтропия расстояние кульбака лейблера хаос закон неубывания энтропии энергия второе начало термодинамики принцип ландауэра телеономия примечания литература категория теория хаоса категория потенциалы категория релятивистские инварианты