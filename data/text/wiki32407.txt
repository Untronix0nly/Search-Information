арифметическое кодирование один из алгоритмов энтропийного сжатия отличие от алгоритма хаффмана не имеет жесткого постоянного соответствия входных символов группам бит выходного потока это даёт алгоритму большую гибкость представлении дробных частот встречаемости символов как правило превосходит алгоритм хаффмана по эффективности сжатия позволяет сжимать данные энтропией меньшей бита на кодируемый символ но некоторые версии имеют патентные ограничения от компании ibm характеристики обеспечивает почти оптимальную степень сжатия точки зрения энтропийной оценки кодирования шеннона на каждый символ требуется почти бит где информационная энтропия источника отличие от алгоритма хаффмана метод арифметического кодирования показывает высокую эффективность для дробных неравномерных интервалов распределения вероятностей кодируемых символов однако случае равновероятного распределения символов например для строки бит длины метод арифметического кодирования приближается префиксному коду хаффмана даже может занимать на один бит больше принцип действия пусть имеется некий алфавит также данные частотности использования символов опционально тогда рассмотрим на координатной прямой отрезок от до назовём этот отрезок рабочим расположим на нём точки таким образом что длины образованных отрезков будут равны частоте использования символа каждый такой отрезок будет соответствовать одному символу теперь возьмём символ из потока найдём для него отрезок среди только что сформированных теперь отрезок для этого символа стал рабочим разобьём его таким же образом как разбили отрезок от до выполним эту операцию для некоторого числа символов затем выберем любое число из рабочего отрезка биты этого числа вместе длиной его битовой записи есть результат арифметического кодирования использованных символов потока пример работы метода арифметического кодирования вероятностная модель используя метод арифметического кодирования можно достичь почти оптимального представления для заданного набора символов их вероятностей согласно теории энтропийного кодирования источника шеннона оптимальное представление будет стремиться числу log бит на каждый символ вероятность которого алгоритмы сжатия данных использующие своей работе метод арифметического кодирования перед кодированием формируют модель входных данных на основании количественных или статистических характеристик также найденных кодируемой повторений или паттернов любой дополнительной информации позволяющей уточнить вероятность появления символа процессе кодирования очевидно что чем точнее определена или предсказана вероятность символа тем выше эффективность сжатия рассмотрим простейший случай статической модели для кодирования информации поступающей системы обработки сигнала типы сигналов соответствующие им вероятности распределены следующим образом вероятность нейтрального значения сигнала или neutral вероятность положительного значения сигнала или positive вероятность отрицательного значения сигнала или negative вероятность признака конца кодируемой или end of data появление последнего символа для декодера означает что вся была успешно декодирована качестве альтернативного подхода но необязательно более успешно можно использовать блочный алгоритм фиксированной длины следует также отметить что качестве алфавита вероятностной модели метода можно рассматривать любой набор символов исходя из особенностей решаемой задачи более эвристические подходы использующие основную схему метода арифметического кодирования применяют динамические или адаптивные модели идея данных методов заключается уточнении вероятности кодируемого символа за счёт учёта вероятности предшествующего или будущего контекста то есть вероятность появления кодируемого символа после определённого го числа символов слева или справа где это порядок контекста кодирование сообщения возьмём для примера следующую neutral positive negative end of data сначала разобьём отрезок от до согласно частотам сигналов разбивать отрезок будем порядке указанном выше neutral от до positive от до negative от до end of data от до теперь начнём кодировать первого символа первому символу neutral соответствует отрезок от до разобьём этот отрезок аналогично отрезку от до закодируем второй символ negative на отрезке от до ему соответствует отрезок от до разобьём этот отрезок аналогично отрезку от до закодируем третий символ end of data на отрезке от до ему соответствует отрезок от до так как это был последний символ то кодирование завершено закодированное сообщение отрезок от до или любое число из него например декодирование сообщения на диаграмме представлено декодирование итогового интервального значения согласно модели приведённом примере область интервала разбивается на подинтервальные области согласно вероятностным характеристикам появления соответствующих символов затем очередной выбранный интервал разбивается аналогичным способом предположим что нам необходимо раскодировать сообщение методом арифметического кодирования согласно описанной выше модели сообщение закодированном виде представлено дробным значением для простоты используется десятичное представление дроби вместо двоичного основания предполагается что закодированное сообщение содержит ровно столько знаков рассматриваемом числе сколько необходимо для однозначного восстановления первоначальных данных начальное состояние процесса декодирования совпадает процессом кодирования рассматривается интервал на основании известной вероятностной модели дробное значение попадает интервал это позволяет определить первый символ который был выбран кодировщиком поэтому его значение выводится как первый символ декодированного сообщения примечания ссылки august dr dobb data compression newsletter категория теория кодирования категория сжатие данных категория алгоритмы сжатия без потерь