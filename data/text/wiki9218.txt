схема простой нейросети зелёным цветом обозначены входные нейроны голубым скрытые нейроны жёлтым выходной нейрон иску сственная нейро нная се ть инс математическая модель также её программное или аппаратное воплощение построенная по принципу организации биологических нейронных сетей сетей нервных клеток живого организма это понятие возникло при изучении процессов протекающих мозге при попытке смоделировать эти процессы первой такой попыткой были нейронные сети маккалока питтса после разработки алгоритмов обучения получаемые модели стали использовать практических целях задачах прогнозирования для распознавания образов задачах управления др инс представляет собой систему соединённых между собой простых процессоров искусственных нейронов такие процессоры обычно довольно просты особенно сравнении процессорами используемыми персональных компьютерах каждый процессор подобной сети имеет дело только сигналами которые он периодически получает сигналами которые он периодически посылает другим процессорам тем не менее будучи соединёнными достаточно большую сеть управляемым взаимодействием такие по отдельности простые процессоры вместе способны выполнять довольно сложные задачи точки зрения машинного обучения нейронная сеть представляет собой частный случай методов распознавания образов анализа методов кластеризации математической точки зрения обучение нейронных сетей это задача нелинейной оптимизации точки зрения кибернетики нейронная сеть используется задачах адаптивного управления как алгоритмы для робототехники точки зрения развития вычислительной техники нейронная сеть способ решения проблемы эффективного параллелизма точки зрения искусственного интеллекта инс является основой философского течения коннективизма основным направлением структурном подходе по изучению возможности построения моделирования естественного интеллекта помощью компьютерных алгоритмов нейронные сети не программируются привычном смысле этого слова они обучаются возможность обучения одно из главных преимуществ нейронных сетей перед традиционными алгоритмами технически обучение заключается нахождении коэффициентов связей между нейронами процессе обучения нейронная сеть способна выявлять сложные зависимости между входными данными выходными также выполнять обобщение это значит что случае успешного обучения сеть сможет вернуть верный результат на основании данных которые отсутствовали обучающей выборке также неполных или зашумленных частично искажённых данных хронология маккалок питтс формализуют понятие нейронной сети фундаментальной статье логическом исчислении идей нервной активности начале своего сотрудничества питтсом винер предлагает ему вакуумные лампы качестве идеального на тот момент средства для реализации эквивалентов нейронных сетей винер вместе соратниками кибернетике основной идеей является представление сложных биологических процессов математическими моделями хебб предлагает первый алгоритм обучения розенблатт изобретает однослойный перцептрон демонстрирует его способность решать задачи классификации перцептрон обрёл популярность его используют для распознавания образов прогнозирования погоды то время казалось что уже не за горами создание полноценного искусственного интеллекта моменту изобретения перцептрона завершилось расхождение теоретических работ маккалока кибернетикой винера маккалок его последователи вышли из состава клуба году совместно со своим студентом хоффом на основе дельта правила формулы уидроу разработали адалин который сразу начал использоваться для задач предсказания адаптивного управления адалин был построен на базе созданных ими же уидроу хоффом принципиально новых элементах мемисторах сейчас адалин адаптивный сумматор является стандартным элементом многих систем обработки сигналов году институте проблем передачи информации ан ссср петровым проводится подробное исследование задач трудных для перцептрона эта пионерская работа области моделирования инс ссср послужила отправной точкой для комплекса идей бонгарда как сравнительно небольшой переделкой алгоритма перцептрона исправить его недостатки работы петрова бонгарда весьма способствовали тому что ссср первая волна эйфории по поводу инс была сглажена году минский публикует формальное доказательство ограниченности перцептрона показывает что он неспособен решать некоторые задачи проблема чётности один блоке связанные инвариантностью представлений интерес нейронным сетям резко спадает году кохонен независимо предлагают новый тип нейронных сетей способных функционировать качестве памяти году хакимов предлагает нелинейную модель синапсами на основе сплайнов внедряет её для решения задач медицине геологии экологии пол дж вербос галушкин одновременно изобретают алгоритм обратного распространения ошибки для обучения многослойных перцептронов изобретение не привлекло особого внимания фукусима представляет когнитрон сеть предназначенную для инвариантного распознавания образов но это достигается только при помощи запоминания практически всех состояний образа после периода забвения интерес нейросетям вновь возрастает дж хопфилд показал что нейронная сеть обратными связями может представлять собой систему минимизирующую энергию так называемая сеть хопфилда кохоненом представлены модели сети обучающейся без учителя нейронная сеть кохонена решающей задачи кластеризации визуализации данных карта кохонена другие задачи анализа данных дэвидом румельхартом дж хинтоном рональдом дж вильямсом независимо одновременно барцевым охониным красноярская группа переоткрыт существенно развит метод обратного распространения ошибки начался взрыв интереса обучаемым нейронным сетям джеффри хинтоном университете торонто созданы алгоритмы глубокого обучения многослойных нейронных сетей успех обусловлен тем что хинтон при обучении нижних слоев сети использовал ограниченную машину больцмана rbm restricted boltzmann machine глубокое обучение по хинтону это очень медленный процесс необходимо использовать много примеров распознаваемых образов например множество лиц людей на разных фонах после обучения получается готовое быстро работающее приложение способное решать конкретную задачу например осуществлять поиск лиц на изображении функция поиска лиц людей на сегодняшний день стала стандартной встроена во все современные цифровые фотоаппараты технология глубокого обучения активно используется интернет поисковиками при классификации картинок по содержащимся них образам применяемые при распознавании искусственные нейронные сети могут иметь до слоёв нейронов их обучение ведётся на миллионах изображений отыскиваемым образом известные применения распознавание образов классификация качестве образов могут выступать различные по своей природе объекты символы текста изображения образцы звуков при обучении сети предлагаются различные образцы образов указанием того какому классу они относятся образец как правило представляется как вектор значений признаков при этом совокупность всех признаков должна однозначно определять класс которому относится образец случае если признаков недостаточно сеть может соотнести один тот же образец несколькими классами что неверно по окончании обучения сети ей можно предъявлять неизвестные ранее образы получать ответ принадлежности определённому классу топология такой сети характеризуется тем что количество нейронов выходном слое как правило равно количеству определяемых классов при этом устанавливается соответствие между выходом нейронной сети классом который он представляет когда сети предъявляется некий образ на одном из её выходов должен появиться признак того что образ принадлежит этому классу то же время на других выходах должен быть признак того что образ данному классу не принадлежит если на двух или более выходах есть признак принадлежности классу считается что сеть не уверена своём ответе используемые архитектуры нейросетей обучение учителем перцептрон обучение без учителя сети адаптивного резонанса смешанное обучение сеть радиально базисных функций принятие решений управление эта задача близка задаче классификации классификации подлежат ситуации характеристики которых поступают на вход нейронной сети на выходе сети при этом должен появиться признак решения которое она приняла при этом качестве входных сигналов используются различные критерии описания состояния управляемой системы используемые архитектуры нейросетей обучение учителем перцептрон смешанное обучение сеть радиально базисных функций кластеризация под кластеризацией понимается разбиение множества входных сигналов на классы при том что ни количество ни признаки классов заранее не известны после обучения такая сеть способна определять какому классу относится входной сигнал сеть также может сигнализировать том что входной сигнал не относится ни одному из выделенных классов это является признаком новых отсутствующих обучающей выборке данных таким образом подобная сеть может выявлять новые неизвестные ранее классы сигналов соответствие между классами выделенными сетью классами существующими предметной области устанавливается человеком кластеризацию осуществляют например нейронные сети кохонена нейронные сети простом варианте кохонена не могут быть огромными поэтому их делят на гиперслои гиперколонки ядра микроколонки если сравнивать мозгом человека то идеальное количество параллельных слоёв не должно быть более эти слои свою очередь составляют гиперслои гиперколонку которой от до микроколонок ядер при этом каждый слой делится на множество гиперколонок пронизывающих насквозь эти слои микроколонки кодируются цифрами единицами получением результата на выходе если требуется то лишние слои нейроны удаляются или добавляются идеально для подбора числа нейронов слоёв использовать суперкомпьютер такая система позволяет нейронным сетям быть пластичными используемые архитектуры нейросетей обучение без учителя перцептрон карта кохонена нейронная сеть кохонена сети адаптивного резонанса прогнозирование способности нейронной сети прогнозированию напрямую следуют из её способности обобщению выделению скрытых зависимостей между входными выходными данными после обучения сеть способна предсказать будущее значение некой на основе нескольких предыдущих значений или каких то существующих настоящий момент факторов следует отметить что прогнозирование возможно только тогда когда предыдущие изменения действительно какой то степени предопределяют будущие например прогнозирование котировок акций на основе котировок за прошлую неделю может оказаться успешным может не оказаться тогда как прогнозирование результатов завтрашней лотереи на основе данных за последние лет почти наверняка не даст никаких результатов используемые архитектуры нейросетей обучение учителем перцептрон смешанное обучение сеть радиально базисных функций аппроксимация нейронные сети могут непрерывные функции доказана обобщённая теорема помощью линейных операций каскадного соединения можно из произвольного нелинейного элемента получить устройство вычисляющее любую непрерывную функцию некоторой наперёд заданной точностью это означает что нелинейная характеристика нейрона может быть произвольной от сигмоидальной до произвольного волнового пакета или вейвлета синуса или многочлена от выбора нелинейной функции может зависеть сложность конкретной сети но любой нелинейностью сеть остаётся универсальным аппроксиматором при правильном выборе структуры может достаточно точно любого непрерывного автомата используемые архитектуры нейросетей обучение учителем перцептрон смешанное обучение сеть радиально базисных функций сжатие данных ассоциативная память способность нейросетей выявлению взаимосвязей между различными параметрами дает возможность выразить данные большой размерности более компактно если данные тесно взаимосвязаны друг другом обратный процесс восстановление исходного набора данных из части информации называется авто ассоциативной памятью ассоциативная память позволяет также восстанавливать исходный сигнал образ из зашумленных поврежденных входных данных решение задачи памяти позволяет реализовать память адресуемую по содержимому используемые архитектуры нейросетей обучение учителем перцептрон обучение без учителя нейронная сеть хопфилда анализ данных используемые архитектуры нейросетей обучение учителем перцептрон обучение без учителя перцептрон карта кохонена нейронная сеть кохонена оптимизация используемые архитектуры нейросетей обучение без учителя карта кохонена нейронная сеть кохонена этапы решения задач сбор данных для обучения подготовка нормализация данных выбор топологии сети подбор характеристик сети подбор параметров обучения собственно обучение проверка адекватности обучения корректировка параметров окончательное обучение вербализация сети целью дальнейшего использования следует рассмотреть подробнее некоторые из этих этапов сбор данных для обучения выбор данных для обучения сети их обработка является самым сложным этапом решения задачи набор данных для обучения должен удовлетворять нескольким критериям данные должны иллюстрировать истинное положение вещей предметной области противоречивые данные обучающей выборке приведут плохому качеству обучения сети исходные данные преобразуются виду котором их можно подать на входы сети каждая запись файле данных называется обучающей парой или обучающим вектором обучающий вектор содержит по одному значению на каждый вход сети зависимости от типа обучения учителем или без по одному значению для каждого выхода сети обучение сети на сыром наборе как правило не даёт качественных результатов существует ряд способов улучшить восприятие сети нормировка выполняется когда на различные входы подаются данные разной размерности например на первый вход сети подаются величины со значениями от нуля до единицы на второй от ста до тысячи при отсутствии нормировки значения на втором входе будут всегда оказывать существенно большее влияние на выход сети чем значения на первом входе при нормировке размерности всех входных выходных данных сводятся воедино квантование выполняется над непрерывными величинами для которых выделяется конечный набор дискретных значений например квантование используют для задания частот звуковых сигналов при распознавании речи фильтрация выполняется для зашумленных данных кроме того большую роль играет само представление как входных так выходных данных предположим сеть обучается распознаванию букв на изображениях имеет один числовой выход номер буквы алфавите этом случае сеть получит ложное представление том что буквы номерами более похожи чем буквы номерами что общем неверно для того чтобы избежать такой ситуации используют топологию сети большим числом выходов когда каждый выход имеет свой смысл чем больше выходов сети тем большее расстояние между классами тем сложнее их спутать выбор топологии сети выбирать тип сети следует исходя из постановки задачи имеющихся данных для обучения для обучения учителем требуется наличие для каждого элемента выборки экспертной оценки иногда получение такой оценки для большого массива данных просто невозможно этих случаях естественным выбором является сеть обучающаяся без учителя например карта кохонена или нейронная сеть хопфилда при решении других задач таких как прогнозирование временных рядов экспертная оценка уже содержится исходных данных может быть выделена при их обработке этом случае можно использовать многослойный перцептрон или сеть ворда подбор характеристик сети после выбора общей структуры нужно подобрать параметры сети для сетей подобных перцептрону это будет число слоев число блоков скрытых слоях для сетей ворда наличие или отсутствие обходных соединений передаточные функции нейронов при выборе количества слоев нейронов них следует исходить из того что способности сети обобщению тем выше чем больше суммарное число связей между нейронами другой стороны число связей ограничено сверху количеством записей обучающих данных подбор параметров обучения после выбора конкретной топологии необходимо выбрать параметры обучения нейронной сети этот этап особенно важен для сетей обучающихся учителем от правильного выбора параметров зависит не только то насколько быстро ответы сети будут сходиться правильным ответам например выбор низкой скорости обучения увеличит время схождения однако иногда позволяет избежать паралича сети увеличение момента обучения может привести как увеличению так уменьшению времени сходимости зависимости от формы поверхности ошибки исходя из такого противоречивого влияния параметров можно сделать вывод что их значения нужно выбирать руководствуясь при этом критерием завершения обучения например минимизация ошибки или ограничение по времени обучения обучение сети процессе обучения сеть определённом порядке просматривает обучающую выборку порядок просмотра может быть случайным некоторые сети обучающиеся без учителя например сети хопфилда просматривают выборку только один раз другие например сети кохонена также сети обучающиеся учителем просматривают выборку множество раз при этом один полный проход по выборке называется эпохой обучения при обучении учителем набор исходных данных делят на две части собственно обучающую выборку тестовые данные принцип разделения может быть произвольным обучающие данные подаются сети для обучения проверочные используются для расчета ошибки сети проверочные данные никогда для обучения сети не применяются таким образом если на проверочных данных ошибка уменьшается то сеть действительно выполняет обобщение если ошибка на обучающих данных продолжает уменьшаться ошибка на тестовых данных увеличивается значит сеть перестала выполнять обобщение просто запоминает обучающие данные это явление называется переобучением сети или оверфиттингом таких случаях обучение обычно прекращают процессе обучения могут проявиться другие проблемы такие как паралич или попадание сети локальный минимум поверхности ошибок невозможно заранее предсказать проявление той или иной проблемы равно как дать однозначные рекомендации их разрешению все выше сказанное относится только итерационным алгоритмам поиска нейросетевых решений для них действительно нельзя ничего гарантировать нельзя полностью обучение нейронных сетей однако наряду итерационными алгоритмами обучения существуют не итерационные алгоритмы обладающие очень высокой устойчивостью позволяющие полностью процесс обучения проверка адекватности обучения даже случае успешного на первый взгляд обучения сеть не всегда обучается именно тому чего от неё хотел создатель известен случай когда сеть обучалась распознаванию изображений танков по фотографиям однако позднее выяснилось что все танки были на одном том же фоне результате сеть научилась распознавать этот тип ландшафта вместо того чтобы научиться распознавать танки таким образом сеть понимает не то что от неё требовалось то что проще всего обобщить тестирование качества обучения нейросети необходимо проводить на примерах которые не участвовали её обучении при этом число тестовых примеров должно быть тем больше чем выше качество обучения если ошибки нейронной сети имеют вероятность близкую одной миллиардной то для подтверждения этой вероятности нужен миллиард тестовых примеров получается что тестирование хорошо обученных нейронных сетей становится очень трудной задачей классификация по типу входной информации аналоговые нейронные сети используют информацию форме действительных чисел двоичные нейронные сети оперируют информацией представленной двоичном виде образные нейронные сети оперируют информацией представленной виде образов знаков иероглифов символов классификация по характеру обучения обучение учителем выходное пространство решений нейронной сети известно обучение без учителя нейронная сеть формирует выходное пространство решений только на основе входных воздействий такие сети называют обучение подкреплением система назначения штрафов поощрений от среды классификация по характеру настройки синапсов сети фиксированными связями весовые коэффициенты нейронной сети выбираются сразу исходя из условий задачи при этом где весовые коэффициенты сети сети динамическими связями для них процессе обучения происходит настройка синаптических связей то есть где весовые коэффициенты сети классификация по времени передачи сигнала ряде нейронных сетей активирующая функция может зависеть не только от весовых коэффициентов связей но от времени передачи импульса сигнала по каналам связи поэтому общем виде активирующая передающая функция связи от элемента элементу имеет вид тогда синхронной сетью называют такую сеть которой время передачи каждой связи равно либо нулю либо фиксированной постоянной асинхронной называют такую сеть которой время передачи для каждой связи между элементами своё но тоже постоянное классификация по характеру связей сети прямого распространения feedforward все связи направлены строго от входных нейронов выходным примерами таких сетей являются перцептрон розенблатта многослойный перцептрон сети ворда рекуррентные нейронные сети сигнал выходных нейронов или нейронов скрытого слоя частично передается обратно на входы нейронов входного слоя обратная связь рекуррентная сеть хопфилда фильтрует входные данные возвращаясь устойчивому состоянию таким образом позволяет решать задачи компрессии данных построения ассоциативной памяти частным случаем рекуррентных сетей являются двунаправленные сети таких сетях между слоями существуют связи как направлении от входного слоя выходному так обратном классическим примером является нейронная сеть коско радиально базисные функции разработаны искусственные нейронные сети использующие качестве активационных функций радиально базисные также называются rbf сетями общий вид радиально базисной функции например где вектор входных сигналов нейрона ширина окна функции убывающая функция чаще всего равная нулю вне некоторого отрезка радиально базисная сеть характеризуется тремя особенностями единственный скрытый слой только нейроны скрытого слоя имеют нелинейную активационную функцию синаптические веса связей входного скрытого слоев равны единице карты такие сети представляют собой нейронную сеть обучением без учителя выполняющую задачу визуализации кластеризации является методом проецирования многомерного пространства пространство более низкой размерностью чаще всего двумерное применяется также для решения задач моделирования прогнозирования др является одной из версий нейронных сетей кохонена карты кохонена служат первую очередь для визуализации первоначального анализа данных сигнал сеть кохонена поступает сразу на все нейроны веса соответствующих синапсов как координаты положения узла выходной сигнал формируется по принципу победитель забирает всё то есть ненулевой выходной сигнал имеет нейрон ближайший смысле весов синапсов подаваемому на вход объекту процессе обучения веса синапсов настраиваются таким образом чтобы узлы решетки располагались местах локальных сгущений данных то есть описывали кластерную структуру облака данных другой стороны связи между нейронами соответствуют отношениям соседства между кластерами пространстве признаков удобно рассматривать такие карты как двумерные сетки узлов размещенных многомерном пространстве изначально карта представляет собой сетку из узлов соединенную между собой связями кохонен рассматривал два варианта соединения узлов прямоугольную гексагональную сетку отличие состоит том что прямоугольной сетке каждый узел соединён соседними гексагональной шестью ближайшими узлами для двух таких сеток процесс построения сети кохонена отличается лишь том месте где перебираются ближайшие данному узлу соседи начальное вложение сетки пространство данных выбирается произвольным образом авторском пакете som_pak предлагаются варианты случайного начального расположения узлов пространстве вариант расположения узлов плоскости после этого узлы начинают перемещаться пространстве согласно следующему алгоритму случайным образом выбирается точка данных определяется ближайший узел карты bmu best matching unit этот узел перемещается на заданный шаг по направлению однако он перемещается не один увлекает за собой определённое количество ближайших узлов из некоторой окрестности на карте из всех двигающихся узлов наиболее сильно смещается центральный ближайший точке данных узел остальные испытывают тем меньшие смещения чем дальше они от bmu настройке карты различают два этапа этап грубой ordering этап тонкой fine tuning настройки на первом этапе выбираются большие значения окрестностей движение узлов носит коллективный характер результате карта расправляется грубым образом отражает структуру данных на этапе тонкой настройки радиус окрестности равен настраиваются уже индивидуальные положения узлов кроме этого величина смещения равномерно затухает со временем то есть она велика начале каждого из этапов обучения близка нулю конце алгоритм повторяется определённое число эпох понятно что число шагов может сильно изменяться зависимости от задачи известные типы сетей перцептрон розенблатта сплайн модель хакимова многослойный перцептрон розенблатта многослойный перцептрон румельхарта сеть джордана сеть элмана сеть хэмминга сеть ворда сеть хопфилда сеть кохонена нейронный газ когнитрон неокогнитрон хаотическая нейронная сеть осцилляторная нейронная сеть сеть встречного распространения сеть радиально базисных функций rbf сеть сеть обобщённой регрессии сеть смирнова вероятностная сеть вероятностная нейронная сеть решетова сиамская нейронная сеть сети адаптивного резонанса свёрточная нейронная сеть нечёткий многослойный перцептрон импульсная нейронная сеть отличия от машин архитектурой фон неймана вычислительные системы основанные на искусственных нейронных сетях обладают рядом качеств которые отсутствуют машинах архитектурой фон неймана но присущи мозгу человека массовый параллелизм распределённое представление информации вычисления способность обучению обобщению адаптивность свойство контекстуальной обработки информации толерантность ошибкам низкое примеры приложений предсказание финансовых временных рядов входные данные курс акций за год задача определить завтрашний курс проводится следующее преобразование выстраивается ряд курс за сегодня вчера за позавчера следующий ряд смещается по дате на один день так далее на полученном наборе обучается сеть входами одним выходом то есть выход курс на дату входы курс на дату минус день минус дня минус дня обученной сети подаем на вход курс за сегодня вчера позавчера получаем ответ на завтра нетрудно заметить что этом случае сеть просто выведет зависимость одного параметра от трёх предыдущих если желательно учитывать ещё какой то параметр например общий индекс по отрасли то его надо добавить как вход включить примеры переобучить сеть получить новые результаты для наиболее точного обучения стоит использовать метод оро как наиболее предсказуемый несложный реализации серия работ доррера соавторами посвящена исследованию вопроса возможности развития психологической интуиции нейросетевых экспертных систем полученные результаты дают подход раскрытию механизма интуиции нейронных сетей проявляющейся при решении ими задач создан нестандартный для компьютерных методик интуитивный подход заключающийся исключении построения описанной реальности он позволяет сократить упростить работу над методиками хемоинформатика нейронные сети широко используются химических биохимических исследованиях настоящее время нейронные сети являются одним из самых методов хемоинформатики для поиска количественных соотношений структура свойство благодаря чему они активно используются как для прогнозирования физико химических свойств биологической активности химических соединений так для направленного дизайна химических соединений материалов заранее заданными свойствами том числе при разработке новых лекарственных препаратов нейроуправление нейронные сети успешно применяются для синтеза систем управления динамическими объектами нейросети обладают рядом уникальных свойств которые делают их мощным инструментом для создания систем управления способностью обучению на примерах обобщению данных способностью адаптироваться изменению свойств объекта управления внешней среды пригодностью для синтеза нелинейных регуляторов высокой устойчивостью повреждениям своих элементов силу изначально заложенного нейросетевую архитектуру параллелизма экономика алгоритмы искусственных нейронных сетей нашли широкое применение экономике помощью нейронных сетей решается задача разработки алгоритмов нахождения аналитического описания закономерностей экономических объектов предприятие отрасль регион эти алгоритмы применяются прогнозированию некоторых выходных показателей объектов применение нейросетевых методов позволяет решить некоторые проблемы экономико статистического моделирования повысить адекватность математических моделей приблизить их экономической реальности поскольку экономические финансовые социальные системы очень сложны являются результатом человеческих действий противодействий создание полной математической модели учётом всех возможных действий противодействий является очень сложной если разрешимой задачей системах подобной сложности естественным наиболее эффективным является использование моделей которые напрямую имитируют поведение общества экономики именно это способна предложить методология нейронных сетей см также оптические нейронные сети искусственный интеллект нейрокомпьютер blue brain project модель биологического нейрона когнитивистика нейронная сеть примечания литература другие копии онлайн нейрокомпьютер проект стандарта ссылки учебник по искусственным нейронным сетям