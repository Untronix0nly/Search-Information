нейро нная сеть хо пфилда полносвязная нейронная сеть симметричной матрицей связей процессе работы динамика таких сетей сходится конвергирует одному из положений равновесия эти положения равновесия определяются заранее процессе обучения они являются локальными минимумами функционала называемого энергией сети простейшем случае локальными минимумами отрицательно определённой квадратичной формы на мерном кубе такая сеть может быть использована как память как фильтр также для решения некоторых задач оптимизации отличие от многих нейронных сетей работающих до получения ответа через определённое количество тактов сети хопфилда работают до достижения равновесия когда следующее состояние сети точности равно предыдущему начальное состояние является входным образом при равновесии получают выходной образ ее вариацией является нейронная сеть хемминга архитектура сети схема сети хопфилда тремя нейронами нейронная сеть хопфилда устроена так что её отклик на запомненные эталонных образов составляют сами эти образы если образ немного исказить подать на вход он будет восстановлен виде отклика будет получен оригинальный образ таким образом сеть хопфилда осуществляет коррекцию ошибок помех сеть хопфилда однослойная состоит из искусственных нейронов каждый нейрон системы может принимать на входе на выходе одно из двух состояний что аналогично выходу нейрона пороговой функцией активации из за их биполярной природы нейронные сети хопфилда иногда называют спинами каждый нейрон связан со всеми остальными нейронами взаимодействие нейронов сети описывается выражением где элемент матрицы взаимодействий которая состоит из весовых коэффициентов связей между нейронами процессе обучения формируется выходная матрица которая запоминает эталонных образов мерных бинарных векторов эти образы во время эксплуатации сети будут выражать отклик системы на входные сигналы или иначе окончательные значения выходов после серии итераций сети хопфилда матрица связей является симметричной диагональные элементы матрицы полагаются равными нулю что исключает эффект воздействия нейрона на самого себя является необходимым для сети хопфилда но не достаточным условием устойчивости процессе работы сети достаточным является асинхронный режим работы сети подобные свойства определяют тесную связь реальными физическими веществами называемыми спиновыми стёклами матрица взаимодействий хранится на самих нейронах виде весов при связях нейронов другими нейронами так например если входной сигнал определяется параметрами то нейронная сеть хопфилда формируется из одного уровня нейронами каждый нейрон связывается со всеми остальными нейронами таким образом сети образуется связей для каждой связи определяется весовой коэффициент все веса связей образуют матрицу взаимодействий которая заполняется процессе обучения обучение сети обучение сети заключается том что находятся веса матрицы взаимодействий так чтобы запомнить векторов эталонных образов составляющих память системы вычисление коэффициентов основано на следующем правиле для всех запомненных образов матрица связи должна удовлетворять уравнению поскольку именно при этом условии состояния сети будут устойчивы попав такое состояние сеть нём останется запоминаемые векторы должны иметь бинарный вид расчёт весовых коэффициентов проводится по следующей формуле где размерность векторов число запоминаемых выходных векторов номер запоминаемого выходного вектора компонента запоминаемого выходного го вектора это выражение может стать более ясным если заметить что весовая матрица может быть найдена вычислением внешнего произведения каждого запоминаемого вектора самим собой суммированием матриц полученных таким образом это может быть записано виде где запоминаемый вектор столбец расчёт этих весовых коэффициентов называется обучением сети которое проводится только за одну эпоху особенности процесса обучения сети хопфилда алгоритм обучения сети хопфилда существенно отличается от таких классических алгоритмов обучения перцептронов как метод коррекции ошибки или метод обратного распространения ошибки отличие заключается том что вместо приближения нужному состоянию вычислением ошибок все коэффициенты матрицы рассчитываются по одной формуле за один цикл после чего сеть сразу готова работе некоторые авторы относят сеть хопфилда обучению без учителя но это неверно так как обучение без учителя предполагает отсутствие информации том каким классам нужно относить стимулы для сети хопфилда без этой информации нельзя настроить весовые коэффициенты поэтому здесь можно говорить лишь том что такую сеть можно отнести классу оптимизирующих сетей фильтров отличительной особенностью фильтров является то что матрица весовых коэффициентов настраивается алгоритмом раз навсегда затем весовые коэффициенты больше не изменяются это может быть удобно для физического воплощения такого устройства так как на уровне реализовать устройство переменными весовыми коэффициентами на порядок сложнее примером фильтра без обратных связей может служить алгоритм cc cornel classification автором которого является kak сети хопфилда есть обратные связи поэтому нужно решать проблему устойчивости веса между нейронами сети хопфилда могут рассматриваться виде матрицы взаимодействий работе cohen grossberg показано что сеть обратными связями является устойчивой если её матрица симметрична имеет нули на главной диагонали имеется много устойчивых систем другого типа например все сети прямого распространения также современные рекуррентные сети джордана элмана для которых не обязательно выполнять условие на симметрию но это происходит вследствие того что на обратные связи наложены другие ограничения случае сети хопфилда условие симметричности является необходимым но не достаточным том смысле что на достижение устойчивого состояния влияет ещё режим работы сети ниже будет показано что только асинхронный режим работы сети гарантирует достижение устойчивого состояния сети синхронном случае возможно бесконечное переключение между двумя разными состояниями такая ситуация называется динамическим аттрактором то время как устойчивое состояние принято называть статическим аттрактором применение обученной сети пороговая функция реализуемая нейроном сети хопфилда как только веса заданы обученная сеть становится способной распознавать входные сигналы то есть определять какому из запомненных образцов они относятся входной вектор проходит некоторое количество итераций до достижения сходимости конвергенции при этом должны распознаваться частично искажённые или неполные образцы на вход сети сначала придают значения исходного вектора поэтому обозначение на схеме сети входных синапсов явном виде носит чисто условный характер затем сеть последовательно меняет свои состояния согласно формуле где активационная функция текущее следующее состояния сети до тех пор пока состояния не совпадут или случае синхронного режима работы не совпадут состояния одновременно именно этот процесс называется конвергенцией сети полученное устойчивое состояние статический аттрактор или возможно синхронном случае пара динамический аттрактор является ответом сети на данный входной образ на выходе сети может получаться также инверсный вектор котором значения запомненных образцах перевёрнуты случае если система не нашла решения на выходе системы могут получаться также тривиальные вектора состоящие только или только из работа сети режиме фильтрации восстановление повреждённых образов так как сети обратными связями имеют пути передающие сигналы от выходов входам то отклик таких сетей является динамическим то есть после приложения нового входа вычисляется выход передаваясь по сети обратной связи модифицирует вход затем выход повторно вычисляется процесс повторяется снова снова для устойчивой сети итерации приводят все меньшим изменениям выхода пока конце концов выход не становится постоянным для некоторых сетей процесс никогда не заканчивается такие сети называют неустойчивыми проблема устойчивости будет рассмотрена следующем разделе здесь мы рассмотрим основной цикл работы сети как только веса заданы сеть может быть использована для получения запомненного выходного вектора по данному входному вектору который может быть частично неправильным или неполным для этого выходам сети сначала придают значения этого начального вектора затем сеть последовательно меняет свои состояния согласно формуле где активационная функция текущее следующее состояния сети до тех пор пока состояния не совпадут или случае синхронного режима работы не совпадут состояния одновременно именно этот процесс называется конвергенцией сети это же можно описать так называемым локальным полем действующим на нейрон со стороны всех остальных нейронов сети после расчёта локального поля нейрона это значение используется для расчёта значения выхода через функцию активации которая данном случае является пороговой нулевым порогом соответственно значение выхода нейрона текущий момент времени рассчитывается по формуле где весовой коэффициент между нейронами значения выходов нейрона предыдущий момент времени во время работы сети хопфилда признаком нахождения решения является момент когда достигается аттрактор статический когда на каждом следующем шаге повторяется устойчивое состояние или возможно динамический когда до бесконечности чередуются два разных состояния это конечное состояние сети является её реакцией на данный образ нормальным ответом является такое устойчивое состояние которое совпадает одним из запомненных при обучении векторов но при некоторых условиях частности при слишком большом количестве запомненных образов результатом работы может стать так называемый ложный аттрактор химера состоящий из нескольких частей разных запомненных образов синхронном режиме сеть может тому же прийти динамическому аттрактору обе эти ситуации общем случае являются нежелательными поскольку не соответствуют ни одному запомненному вектору соответственно не определяют класс которому сеть отнесла входной образ режимы работы сети хопфилда для сети хопфилда могут существовать две модификации отличающиеся по времени передачи сигнала асинхронный синхронный режимы практически используется только асинхронный режим синхронный режим работы сети если работа сети моделируется на одном процессоре то при синхронном режиме последовательно просматриваются нейроны однако их состояния запоминаются отдельно не меняются до тех пор пока не будут пройдены все нейроны сети когда все нейроны просмотрены их состояния одновременно то есть синхронно отсюда название меняются на новые таким образом достигается моделирование параллельной работы алгоритмом при реально параллельном моделировании этот режим фактически означает что время передачи для каждой связи между элементами одинаково для каждой связи что приводит параллельной работе всех связей они одновременно меняют свои состояния основываясь только на предыдущем моменте времени наличие таких синхронных тактов которые можно легко выделить приводит пониманию синхронного режима при синхронном режиме возможно хотя далеко не всегда наблюдается бесконечное чередование двух состояний разной энергией так называемый динамический аттрактор поэтому синхронный режим практически для сети хопфилда не используется рассматривается лишь как основа для понимания более сложного асинхронного режима асинхронный режим работы сети если моделировать работу сети как алгоритм то асинхронном режиме работы состояния нейронов следующий момент времени меняются последовательно вычисляется локальное поле для первого нейрона момент определяется его реакция нейрон устанавливается новое состояние которое соответствует его выходу момент потом вычисляется локальное поле для второго нейрона учётом нового состояния первого меняется состояние второго нейрона так далее состояние каждого следующего нейрона вычисляется учетом всех изменений состояний рассмотренных ранее нейронов по сути при реализации сети хопфилда явно не видно чём заключается асинхронность но это видно если сеть хопфилда реализовать параллельными вычислениями этом случае асинхронный режим сети хопфилда упрощен носит частный случай по сравнению общим видом асинхронных сетей где время передачи для каждой связи между элементами своё но постоянное чтобы рассмотреть работу сети при параллельной реализации необходимо ввести понятие такта как минимальное время за которое происходит передача сигнала по связи то есть при тогда за промежуток времени между происходит определённое количество тактов именно пределах времени из тактов происходит асинхроность протекания сигналов выполнения расчётов то есть например когда нужно рассчитать состояние нейрона необходимо рассчитать состояние нейрона состояние нейрона умножить это на соответствующие веса но как оказывается чтобы рассчитать состояние нейрона нужно знать обновлённое состояние нейрона старое состояние нейрона умножить их на веса понятно что физически невозможно рассчитать состояние нейрона состояние нейрона за одно то же время так как состояние нейрона зависит от состояния нейрона поэтому связь между нейроном нейроном имеет время передачи достигает нейрона за два такта именное такое разное время передачи позволяет говорить сети хопфилда как сети асинхронным режимом асинхронном режиме невозможен динамический аттрактор вне зависимости от количества запомненных образов начального состояния сеть непременно придёт устойчивому состоянию статическому аттрактору пример восстановления повреждённого изображения если во время обучения сформировать матрицу весовых коэффициентов межнейронных связей на основании эталонных бинарных векторов то нейронная сеть процессе работы под действием описанных выше полей будет менять состояния нейронов до тех пор пока не перейдёт одному из устойчивых состояний пусть имеется нейронная сеть размерностью матрицу связей записан набор чёрно белых картинок чёрный цвет белый среди которых есть изображение собачки рисунок справа если установить начальное состояние сети близким этому вектору рисунок слева искажённый образ то ходе динамики нейронная сеть восстановит исходное изображение эталон этом смысле можно говорить том что сеть хопфилда решает задачу распознавания образов хотя строго говоря полученное эталонное изображение ещё нужно превратить номер класса что некоторых случаях может быть весьма вычислительно ёмкой задачей файл jpg файл hopfielddog jpg искажённый образ эталон устойчивость сети процессе работы принципиальная разница между двумя режимами работы сети состоит том что асинхронном случае сеть обязательно придёт одному устойчивому состоянию при синхронном же возможны ситуации бесконечным циклическим переходом между двумя разными состояниями определить устойчиво или нет состояние нейрона можно на основании так называемой искусственной энергии нейрона данном поле если знак выхода или нейрона совпадает направлением локального поля то его положение энергетически устойчиво следующий момент времени состояние нейрона остаётся неизменным противном случае положение нейрона неустойчиво он меняет свой знак переходя состояние энергией устойчивость при асинхронном способе достигается потому что выполняется условие на общую энергию сети синхронном случае условие несколько изменяется именно ситуации когда происходят бесконечные циклические переходы энергия двух разных состояний соответственно равна при этом состояния также совпадают если образуется такое состояние то его называется динамическим аттрактором если же совпадают состояния аттрактор называют статическим большинстве случаев динамические аттракторы являются нежелательными так как не соответствуют какому либо определённому ответу сети ассоциативная память сеть обратной связью формирует ассоциативную память сеть хопфилда можно отнести памяти то есть такой которая может завершить или исправить образ но не может ассоциировать полученный образ другим образом чтобы организовать устойчивую память помощью сети обратными связями веса нужно выбирать так чтобы образовывать энергетические минимумы нужных вершинах единичного гиперкуба задачи минимизации обработка визуальных образов фильтрация ассоциативная память не единственная область применения модели хопфилда динамическая процедура описанная выше на каждом шаге понижает значение энергии нейронной сети это позволяет решать комбинаторные задачи оптимизации если они могут быть сформулированы как задачи минимизации энергии классической проблемой такого типа является задача коммивояжёра решение задачи коммивояжёре задачу коммивояжера помощью нейронной сети хопфилда решить нельзя сеть хопфилда может использоваться для решения задачи коммивояжера нужно обойти все городов вернуться исходный так чтобы длина пройденного маршрута была минимальной для этого можно наложить например такие требования на сеть сеть должна состоять из нейронов которые мы будем рассматривать как квадрат из строк столбцов ответ сети должен содержать только один активный нейрон каждой строке каждом столбце активный нейрон первом столбце задаёт первый город маршрута во втором столбце второй город маршрута так далее оказывается что для решения этой задачи достаточно следующих простых соображений для выполнения условия веса сети должны быть построены таким образом чтобы каждый нейрон препятствовал активации других нейронов своей строке своём столбце для минимизации длины пути необходимо чтобы нейрон столбце тем активнее препятствовал активации нейронов столбцах чем больше расстояние между ними для того чтобы сеть хопфилда вообще работала необходимо чтобы веса сети не были все отрицательными всем этим условиям удовлетворяет следующая формула вычисления веса между нейроном соответствующим городу на позиции маршруте нейроном соответствующим городу на позиции где некоторые константы расстояние между городами символ кронекера принимающий значение если значение противном случае как легко видеть первый член равен для всех связей той же строке кроме связи нейрона самим собой при второй член равен для всех связей том же столбце кроме связи самим собой третий член пропорционален расстоянию между городами если эти города соседние маршруте или если такую сеть привести случайное начальное состояние то можно ожидать что результирующие стабильное состояние даст нам субоптимальный путь длина которого не слишком превосходит оптимальную сам путь может значительно отличаться от оптимального соответственно для практического применения сеть следует запустить несколько раз выбрать наилучший путь решение данной задачи интересно не столько своим качеством существуют алгоритмы решающие её эффективнее сколько самим подходом задачам оптимизации если возможно перевести условия некоторой задачи параметры связей между нейронами то она может быть относительно неплохо решена сетью без какого либо дополнительного анализа ограничения сети сожалению нейронной сети хопфилда есть ряд недостатков относительно небольшой объём памяти величину которого можно оценить выражением попытка записи бо льшего числа образов приводит тому что нейронная сеть перестаёт их распознавать достижение устойчивого состояния не гарантирует правильный ответ сети это происходит из за того что сеть может сойтись так называемым ложным аттракторам иногда называемым химерами как правило химеры склеены из фрагментов различных образов см также перцептрон рекуррентные нейронные сети нейронная сеть хемминга примечания литература hopfield neural networks and physical systems with emergent collective computational abilities proceedings of national academy of sciences vol no pp april pnas reprint abstract pnas reprint pdf mceliece posner rodemich venkatesh the capacity of the hopfield associative memory ieee transactions on information theory volume issue july kryzhanovsky litinskii mikaelian vector neuron models of associative memory proc of int joint conference on neural networks ijcnn budapest pp kryzhanovsky magomedov mikaelian domain model of neural network doklady mathematics vol pp ссылки лекция по сети хопфилда категория искусственные нейронные сети