{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wiki Corpus Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Импортируем необходимые модули"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.wikicorpus import WikiCorpus\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Функция для парсинга xml файла дампа и создания своего корпуса документов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_files = 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Make_Wiki_Corpus_Single(in_file:str,out_file:str)-> (list,dict):\n",
    "    \"\"\"\n",
    "    Парсит указанный архив(дамп), собирает общую статистику и записывает все в файл\n",
    "    --------------\n",
    "    Params\n",
    "    -------\n",
    "        in_file:str\n",
    "            Путь к файлу(архиву),содержимое которого необходимо распарсить\n",
    "        out_file: str\n",
    "            Путь в файлу для записи распарсенного содержимого\n",
    "    Returns\n",
    "    -------\n",
    "        all_words:list\n",
    "            Список слов, содержащийся во всех документах\n",
    "        statistic_dict:dict\n",
    "            Словарь со статистикой по документам\n",
    "            \n",
    "    Exceptions\n",
    "    ----------\n",
    "        FileNotFoundError\n",
    "    \"\"\"\n",
    "    statistic_dict = dict()\n",
    "    all_words = list()\n",
    "    statistic_dict[\"Число документов\"] = 0\n",
    "    statistic_dict[\"Максимальное число слов\"] = -1\n",
    "    statistic_dict[\"Минимальное число слов\"] = 99999999\n",
    "    statistic_dict[\"Общее число слов\"] = 0\n",
    "    wiki = WikiCorpus(in_file)\n",
    "    if not os.path.exists(in_file):\n",
    "        raise FileNotFoundError(\"Файла в указанной директории нет\")\n",
    "    with open(out_file,'w') as stream:\n",
    "        for article in wiki.get_texts():\n",
    "            statistic_dict[\"Максимальное число слов\"] = len(article) if len(article) >= statistic_dict[\"Максимальное число слов\"] else statistic_dict[\"Максимальное число слов\"] \n",
    "            statistic_dict[\"Минимальное число слов\"]  = len(article) if len(article) <= statistic_dict[\"Минимальное число слов\"] else statistic_dict[\"Минимальное число слов\"]\n",
    "            statistic_dict[\"Общее число слов\"] += len(article)\n",
    "            text = \" \".join(article)\n",
    "            stream.write(bytes(text,'utf-8').decode('utf-8') + \"\\n\")\n",
    "            all_words.extend(article)\n",
    "            statistic_dict[\"Число документов\"]+=1\n",
    "            \n",
    "    statistic_dict[\"Среднее число слов\"] = statistic_dict[\"Общее число слов\"]/statistic_dict[\"Число документов\"]\n",
    "    return all_words,statistic_dict\n",
    "\n",
    "def Make_Wiki_Corpus_Multiple(in_file:str,out_file_prefix:str)-> (list,dict):\n",
    "    statistic_dict = dict()\n",
    "    all_words = list()\n",
    "    statistic_dict[\"Число документов\"] = 0\n",
    "    statistic_dict[\"Максимальное число слов\"] = -1\n",
    "    statistic_dict[\"Минимальное число слов\"] = 999999\n",
    "    statistic_dict[\"Общее число слов\"] = 0\n",
    "    wiki = WikiCorpus(in_file,dictionary = False)\n",
    "    if not os.path.exists(in_file):\n",
    "        raise FileNotFoundError(\"Файла в указанной директории нет\")\n",
    "    for article in wiki.get_texts():\n",
    "        out_file_idx = \"{0}{1}{2}\".format(out_file.split(\".\")[0],str(statistic_dict[\"Число документов\"]),\".txt\")\n",
    "        with open(out_file_idx,\"w\",encoding= 'utf-8') as stream:\n",
    "            statistic_dict[\"Максимальное число слов\"] = len(article) if len(article) >= statistic_dict[\"Максимальное число слов\"] else statistic_dict[\"Максимальное число слов\"]\n",
    "            statistic_dict[\"Минимальное число слов\"]  = len(article) if len(article) <= statistic_dict[\"Минимальное число слов\"] else statistic_dict[\"Минимальное число слов\"]\n",
    "            statistic_dict[\"Общее число слов\"] += len(article)\n",
    "            text = \" \".join(article)\n",
    "            stream.write(bytes(text,'utf-8').decode('utf-8') + \"\\n\")\n",
    "            all_words.extend(article)\n",
    "            statistic_dict[\"Число документов\"]+=1\n",
    "        if(statistic_dict[\"Число документов\"] > 40000):\n",
    "            break\n",
    "    statistic_dict[\"Среднее число слов\"] = statistic_dict[\"Общее число слов\"]/statistic_dict[\"Число документов\"]\n",
    "    return all_words,statistic_dict\n",
    "\n",
    "def Plot_File_Len_Distribution(file_prefix):\n",
    "    for idx in range(number_of_files + 1):\n",
    "        with open(\"{0}{1}{2}\".format()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\untro\\Anaconda31\\lib\\site-packages\\gensim\\utils.py:1254: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "word_list,stats = Make_Wiki_Corpus_Multiple(\"data/ruwiki-20181120-pages-articles-multistream.xml.bz2\",\"data/corpora/wiki.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Число документов': 40001, 'Максимальное число слов': 27416, 'Минимальное число слов': 50, 'Общее число слов': 37004806, 'Среднее число слов': 925.0970225744356}\n"
     ]
    }
   ],
   "source": [
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
